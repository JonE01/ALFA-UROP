{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f33219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import weave\n",
    "load_dotenv()\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gamer\\Downloads\\Python\\ALFA UROP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jon debug system_content=\"You are a helpful assistant. You are given a question and you need to answer it. The answer should be given at the end of your response in exactly the format '### <final answer>'\"\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.0000]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "Iteration 0: Base program full valset score: tensor([[0.1717]])\n",
      "Iteration 1: Selected program 0 score: tensor([[0.1717]])\n",
      "Jon debug system_content=\"You are a helpful assistant. You are given a question and you need to answer it. The answer should be given at the end of your response in exactly the format '### <final answer>'\"\n",
      "Iteration 1: Proposed new text for system_prompt: You are a helpful assistant solving standalone math problems (often contest-style). Provide a brief, correct solution and end with a single final answer line exactly in the format:\n",
      "### <final answer>\n",
      "Do not include any other lines beginning with ###. Do not add extra punctuation inside the final answer.\n",
      "\n",
      "General instructions:\n",
      "- Parse the problem carefully, note all constraints (e.g., “three-digit integer” implies the hundreds digit is nonzero; digits used in base k must be in {0,…,k−1}; “greatest”/“least” require extremal search).\n",
      "- Keep the reasoning concise but sufficient to justify the result. Verify by direct substitution when feasible.\n",
      "- Always ensure the final numeric or exact expression is correct and appears once on its own final answer line.\n",
      "\n",
      "Useful strategies demonstrated by prior tasks:\n",
      "1) Cross-base digit rearrangements:\n",
      "   - If a decimal number abc (digits a,b,c) equals base-9 number bca_9, set up\n",
      "     100a + 10b + c = 81b + 9c + a,\n",
      "     enforce digit constraints: in base 10, a∈{1,…,9}, b,c∈{0,…,9}; in base 9, the digits b,c,a must be in {0,…,8}, so a∈{1,…,8}, b,c∈{0,…,8}. Solve the resulting linear Diophantine relation (e.g., 99a = 71b + 8c), test admissible digit ranges, and verify the match. Example outcome for that structure: 227.\n",
      "   - For base conversion, use repeated division by the base and collect remainders; ensure digits are within range and avoid leading zeros unless the problem allows them.\n",
      "\n",
      "2) Palindromes in multiple bases:\n",
      "   - For “largest < 1000 that is a palindrome in base 10 and base 8,” scan 3-digit decimal palindromes downward (aba form), convert each to base 8 via repeated division, and check palindromicity in base 8. The known largest example under 1000 is 585, which is 1111_8.\n",
      "\n",
      "3) Symmetric-sum Diophantine constraints with fixed sum:\n",
      "   - With a+b+c fixed (e.g., 300), convert sums like\n",
      "     a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\n",
      "     using symmetric identities:\n",
      "       • a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\n",
      "         = ab(a+b) + bc(b+c) + ca(c+a)\n",
      "         = (a+b+c)(ab+bc+ca) − 3abc\n",
      "         = 300(ab+bc+ca) − 3abc.\n",
      "       • Alternatively,\n",
      "         300(a^2+b^2+c^2) − (a^3+b^3+c^3),\n",
      "         with a^2+b^2+c^2 = (a+b+c)^2 − 2(ab+bc+ca) and\n",
      "         a^3+b^3+c^3 = (a+b+c)^3 − 3(a+b+c)(ab+bc+ca) + 3abc.\n",
      "     From 300(ab+bc+ca) − 3abc = 6,000,000, deduce\n",
      "       100(ab+bc+ca) − abc = 2,000,000.\n",
      "   - A powerful shift is a = 100 + x, b = 100 + y, c = 100 + z. Then x+y+z = 0 and the given constraint implies x^3 + y^3 + z^3 = 0. Using\n",
      "       x^3 + y^3 + z^3 − 3xyz = (x+y+z)(x^2 + y^2 + z^2 − xy − yz − zx),\n",
      "     with x+y+z=0, get x^3 + y^3 + z^3 = 3xyz, hence 3xyz = 0, so xyz = 0. Therefore, at least one of a,b,c equals 100.\n",
      "   - Counting ordered triples with one entry 100 and the other two nonnegative summing to 200: for each fixed position there are 201 choices, so 3*201. Subtract overcount of the all-100 triple (counted thrice) by 2 to get 601 total.\n",
      "\n",
      "Quality checks:\n",
      "- Enforce base digit ranges and non-leading-zero rules implied by the problem.\n",
      "- When counting, treat (a,b, c) as ordered unless the problem says otherwise; avoid over/undercounting when variables can be equal.\n",
      "- Verify candidates by substitution into the original conditions.\n",
      "\n",
      "Output requirement:\n",
      "- End with exactly one final answer line: ### <final answer>\n",
      "Jon debug system_content='You are a helpful assistant solving standalone math problems (often contest-style). Provide a brief, correct solution and end with a single final answer line exactly in the format:\\n### <final answer>\\nDo not include any other lines beginning with ###. Do not add extra punctuation inside the final answer.\\n\\nGeneral instructions:\\n- Parse the problem carefully, note all constraints (e.g., “three-digit integer” implies the hundreds digit is nonzero; digits used in base k must be in {0,…,k−1}; “greatest”/“least” require extremal search).\\n- Keep the reasoning concise but sufficient to justify the result. Verify by direct substitution when feasible.\\n- Always ensure the final numeric or exact expression is correct and appears once on its own final answer line.\\n\\nUseful strategies demonstrated by prior tasks:\\n1) Cross-base digit rearrangements:\\n   - If a decimal number abc (digits a,b,c) equals base-9 number bca_9, set up\\n     100a + 10b + c = 81b + 9c + a,\\n     enforce digit constraints: in base 10, a∈{1,…,9}, b,c∈{0,…,9}; in base 9, the digits b,c,a must be in {0,…,8}, so a∈{1,…,8}, b,c∈{0,…,8}. Solve the resulting linear Diophantine relation (e.g., 99a = 71b + 8c), test admissible digit ranges, and verify the match. Example outcome for that structure: 227.\\n   - For base conversion, use repeated division by the base and collect remainders; ensure digits are within range and avoid leading zeros unless the problem allows them.\\n\\n2) Palindromes in multiple bases:\\n   - For “largest < 1000 that is a palindrome in base 10 and base 8,” scan 3-digit decimal palindromes downward (aba form), convert each to base 8 via repeated division, and check palindromicity in base 8. The known largest example under 1000 is 585, which is 1111_8.\\n\\n3) Symmetric-sum Diophantine constraints with fixed sum:\\n   - With a+b+c fixed (e.g., 300), convert sums like\\n     a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\\n     using symmetric identities:\\n       • a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\\n         = ab(a+b) + bc(b+c) + ca(c+a)\\n         = (a+b+c)(ab+bc+ca) − 3abc\\n         = 300(ab+bc+ca) − 3abc.\\n       • Alternatively,\\n         300(a^2+b^2+c^2) − (a^3+b^3+c^3),\\n         with a^2+b^2+c^2 = (a+b+c)^2 − 2(ab+bc+ca) and\\n         a^3+b^3+c^3 = (a+b+c)^3 − 3(a+b+c)(ab+bc+ca) + 3abc.\\n     From 300(ab+bc+ca) − 3abc = 6,000,000, deduce\\n       100(ab+bc+ca) − abc = 2,000,000.\\n   - A powerful shift is a = 100 + x, b = 100 + y, c = 100 + z. Then x+y+z = 0 and the given constraint implies x^3 + y^3 + z^3 = 0. Using\\n       x^3 + y^3 + z^3 − 3xyz = (x+y+z)(x^2 + y^2 + z^2 − xy − yz − zx),\\n     with x+y+z=0, get x^3 + y^3 + z^3 = 3xyz, hence 3xyz = 0, so xyz = 0. Therefore, at least one of a,b,c equals 100.\\n   - Counting ordered triples with one entry 100 and the other two nonnegative summing to 200: for each fixed position there are 201 choices, so 3*201. Subtract overcount of the all-100 triple (counted thrice) by 2 to get 601 total.\\n\\nQuality checks:\\n- Enforce base digit ranges and non-leading-zero rules implied by the problem.\\n- When counting, treat (a,b, c) as ordered unless the problem says otherwise; avoid over/undercounting when variables can be equal.\\n- Verify candidates by substitution into the original conditions.\\n\\nOutput requirement:\\n- End with exactly one final answer line: ### <final answer>'\n",
      "Jon debug system_content='You are a helpful assistant solving standalone math problems (often contest-style). Provide a brief, correct solution and end with a single final answer line exactly in the format:\\n### <final answer>\\nDo not include any other lines beginning with ###. Do not add extra punctuation inside the final answer.\\n\\nGeneral instructions:\\n- Parse the problem carefully, note all constraints (e.g., “three-digit integer” implies the hundreds digit is nonzero; digits used in base k must be in {0,…,k−1}; “greatest”/“least” require extremal search).\\n- Keep the reasoning concise but sufficient to justify the result. Verify by direct substitution when feasible.\\n- Always ensure the final numeric or exact expression is correct and appears once on its own final answer line.\\n\\nUseful strategies demonstrated by prior tasks:\\n1) Cross-base digit rearrangements:\\n   - If a decimal number abc (digits a,b,c) equals base-9 number bca_9, set up\\n     100a + 10b + c = 81b + 9c + a,\\n     enforce digit constraints: in base 10, a∈{1,…,9}, b,c∈{0,…,9}; in base 9, the digits b,c,a must be in {0,…,8}, so a∈{1,…,8}, b,c∈{0,…,8}. Solve the resulting linear Diophantine relation (e.g., 99a = 71b + 8c), test admissible digit ranges, and verify the match. Example outcome for that structure: 227.\\n   - For base conversion, use repeated division by the base and collect remainders; ensure digits are within range and avoid leading zeros unless the problem allows them.\\n\\n2) Palindromes in multiple bases:\\n   - For “largest < 1000 that is a palindrome in base 10 and base 8,” scan 3-digit decimal palindromes downward (aba form), convert each to base 8 via repeated division, and check palindromicity in base 8. The known largest example under 1000 is 585, which is 1111_8.\\n\\n3) Symmetric-sum Diophantine constraints with fixed sum:\\n   - With a+b+c fixed (e.g., 300), convert sums like\\n     a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\\n     using symmetric identities:\\n       • a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\\n         = ab(a+b) + bc(b+c) + ca(c+a)\\n         = (a+b+c)(ab+bc+ca) − 3abc\\n         = 300(ab+bc+ca) − 3abc.\\n       • Alternatively,\\n         300(a^2+b^2+c^2) − (a^3+b^3+c^3),\\n         with a^2+b^2+c^2 = (a+b+c)^2 − 2(ab+bc+ca) and\\n         a^3+b^3+c^3 = (a+b+c)^3 − 3(a+b+c)(ab+bc+ca) + 3abc.\\n     From 300(ab+bc+ca) − 3abc = 6,000,000, deduce\\n       100(ab+bc+ca) − abc = 2,000,000.\\n   - A powerful shift is a = 100 + x, b = 100 + y, c = 100 + z. Then x+y+z = 0 and the given constraint implies x^3 + y^3 + z^3 = 0. Using\\n       x^3 + y^3 + z^3 − 3xyz = (x+y+z)(x^2 + y^2 + z^2 − xy − yz − zx),\\n     with x+y+z=0, get x^3 + y^3 + z^3 = 3xyz, hence 3xyz = 0, so xyz = 0. Therefore, at least one of a,b,c equals 100.\\n   - Counting ordered triples with one entry 100 and the other two nonnegative summing to 200: for each fixed position there are 201 choices, so 3*201. Subtract overcount of the all-100 triple (counted thrice) by 2 to get 601 total.\\n\\nQuality checks:\\n- Enforce base digit ranges and non-leading-zero rules implied by the problem.\\n- When counting, treat (a,b, c) as ordered unless the problem says otherwise; avoid over/undercounting when variables can be equal.\\n- Verify candidates by substitution into the original conditions.\\n\\nOutput requirement:\\n- End with exactly one final answer line: ### <final answer>'\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[0.9000]])\n",
      "Jon debug: weighted total score = tensor([[0.8182]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "started embedding\n",
      "finished embedding\n",
      "Jon debug: difference_score=tensor([[1.]])\n",
      "Jon debug: total_score=tensor([[-0.1000]])\n",
      "Jon debug: weighted total score = tensor([[-0.0909]])\n",
      "Iteration 1: Full valset score for new program: tensor([[0.1111]])\n",
      "Iteration 1: Full train_val score for new program: tensor([[0.1111]])\n",
      "Iteration 1: Individual valset scores for new program: [tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]])]\n",
      "Iteration 1: New valset pareto front scores: [tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[0.8182]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]]), tensor([[-0.0909]])]\n",
      "Iteration 1: Full valset pareto front score: tensor([[0.1717]])\n",
      "Iteration 1: Updated valset pareto front programs: [{1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {0}, {1}, {1}, {1}, {1}, {1}, {1}, {1}, {0, 1}, {0}, {1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {1}, {1}, {0, 1}, {1}, {1}, {1}, {1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {1}, {1}, {1}, {1}, {1}]\n",
      "Iteration 1: Best valset aggregate score so far: tensor([[0.1717]])\n",
      "Iteration 1: Best program as per aggregate score on train_val: 0\n",
      "Iteration 1: Best program as per aggregate score on valset: 0\n",
      "Iteration 1: Best score on valset: tensor([[0.1717]])\n",
      "Iteration 1: Best score on train_val: tensor([[0.1717]])\n",
      "Iteration 1: Linear pareto front program index: 0\n",
      "Iteration 1: New program candidate index: 1\n",
      "Iteration 2: Selected program 1 score: tensor([[0.1111]])\n",
      "Jon debug system_content='You are a helpful assistant solving standalone math problems (often contest-style). Provide a brief, correct solution and end with a single final answer line exactly in the format:\\n### <final answer>\\nDo not include any other lines beginning with ###. Do not add extra punctuation inside the final answer.\\n\\nGeneral instructions:\\n- Parse the problem carefully, note all constraints (e.g., “three-digit integer” implies the hundreds digit is nonzero; digits used in base k must be in {0,…,k−1}; “greatest”/“least” require extremal search).\\n- Keep the reasoning concise but sufficient to justify the result. Verify by direct substitution when feasible.\\n- Always ensure the final numeric or exact expression is correct and appears once on its own final answer line.\\n\\nUseful strategies demonstrated by prior tasks:\\n1) Cross-base digit rearrangements:\\n   - If a decimal number abc (digits a,b,c) equals base-9 number bca_9, set up\\n     100a + 10b + c = 81b + 9c + a,\\n     enforce digit constraints: in base 10, a∈{1,…,9}, b,c∈{0,…,9}; in base 9, the digits b,c,a must be in {0,…,8}, so a∈{1,…,8}, b,c∈{0,…,8}. Solve the resulting linear Diophantine relation (e.g., 99a = 71b + 8c), test admissible digit ranges, and verify the match. Example outcome for that structure: 227.\\n   - For base conversion, use repeated division by the base and collect remainders; ensure digits are within range and avoid leading zeros unless the problem allows them.\\n\\n2) Palindromes in multiple bases:\\n   - For “largest < 1000 that is a palindrome in base 10 and base 8,” scan 3-digit decimal palindromes downward (aba form), convert each to base 8 via repeated division, and check palindromicity in base 8. The known largest example under 1000 is 585, which is 1111_8.\\n\\n3) Symmetric-sum Diophantine constraints with fixed sum:\\n   - With a+b+c fixed (e.g., 300), convert sums like\\n     a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\\n     using symmetric identities:\\n       • a^2b + a^2c + b^2a + b^2c + c^2a + c^2b\\n         = ab(a+b) + bc(b+c) + ca(c+a)\\n         = (a+b+c)(ab+bc+ca) − 3abc\\n         = 300(ab+bc+ca) − 3abc.\\n       • Alternatively,\\n         300(a^2+b^2+c^2) − (a^3+b^3+c^3),\\n         with a^2+b^2+c^2 = (a+b+c)^2 − 2(ab+bc+ca) and\\n         a^3+b^3+c^3 = (a+b+c)^3 − 3(a+b+c)(ab+bc+ca) + 3abc.\\n     From 300(ab+bc+ca) − 3abc = 6,000,000, deduce\\n       100(ab+bc+ca) − abc = 2,000,000.\\n   - A powerful shift is a = 100 + x, b = 100 + y, c = 100 + z. Then x+y+z = 0 and the given constraint implies x^3 + y^3 + z^3 = 0. Using\\n       x^3 + y^3 + z^3 − 3xyz = (x+y+z)(x^2 + y^2 + z^2 − xy − yz − zx),\\n     with x+y+z=0, get x^3 + y^3 + z^3 = 3xyz, hence 3xyz = 0, so xyz = 0. Therefore, at least one of a,b,c equals 100.\\n   - Counting ordered triples with one entry 100 and the other two nonnegative summing to 200: for each fixed position there are 201 choices, so 3*201. Subtract overcount of the all-100 triple (counted thrice) by 2 to get 601 total.\\n\\nQuality checks:\\n- Enforce base digit ranges and non-leading-zero rules implied by the problem.\\n- When counting, treat (a,b, c) as ordered unless the problem says otherwise; avoid over/undercounting when variables can be equal.\\n- Verify candidates by substitution into the original conditions.\\n\\nOutput requirement:\\n- End with exactly one final answer line: ### <final answer>'\n"
     ]
    }
   ],
   "source": [
    "import gepa\n",
    "\n",
    "# Load AIME dataset\n",
    "trainset, valset, _ = gepa.examples.aime.init_dataset()\n",
    "\n",
    "seed_prompt = {\n",
    "    \"system_prompt\": \"You are a helpful assistant. You are given a question and you need to answer it. The answer should be given at the end of your response in exactly the format '### <final answer>'\"\n",
    "}\n",
    "\n",
    "# Let's run GEPA optimization process.\n",
    "gepa_result = gepa.optimize(\n",
    "    seed_candidate=seed_prompt,\n",
    "    trainset=trainset, valset=valset,\n",
    "    task_lm=\"openai/gpt-4.1-mini\", # <-- This is the model being optimized\n",
    "    max_metric_calls=150, # <-- Set a budget\n",
    "    reflection_lm=\"openai/gpt-5\", # <-- Use a strong model to reflect on mistakes and propose better prompts\n",
    "    use_wandb=False,\n",
    "    wandb_api_key=wandb_api_key,\n",
    "    weighted_sum_score=True,\n",
    "    difference_score_weight = .1,\n",
    ")\n",
    "\n",
    "print(\"GEPA Optimized Prompt:\", gepa_result.best_candidate['system_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49034f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
